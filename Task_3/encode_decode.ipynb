{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbbb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "%matplotlib inline\n",
    "\n",
    "train_text = './corpora/WarAndPeace.txt'\n",
    "test_text = './corpora/AnnaKarenina.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5813f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных\n",
    "with open(train_text, 'r') as file:\n",
    "    data_train = file.readlines()\n",
    "data_train = ''.join(data_train)\n",
    "\n",
    "with open(test_text, 'r') as file:\n",
    "    data_test = file.readlines()\n",
    "data_test = ''.join(data_test)\n",
    "\n",
    "train_words = re.findall(r'\\w+', data_train)\n",
    "test_words = re.findall(r'\\w+', data_test)\n",
    "\n",
    "# берем только русские слова\n",
    "alphabyte = ' абвгдежзийклмнопрстуфхцчшщъьыэюя'\n",
    "\n",
    "data_train = []\n",
    "for word in train_words:\n",
    "    word = word.lower()\n",
    "    flag = 0\n",
    "    for char in word:\n",
    "        if char not in alphabyte:\n",
    "            flag = 1\n",
    "            break\n",
    "    if not flag:\n",
    "        data_train += [word]\n",
    "\n",
    "data_test = []\n",
    "for word in test_words:\n",
    "    word = word.lower()\n",
    "    flag = 0\n",
    "    for char in word:\n",
    "        if char not in alphabyte:\n",
    "            flag = 1\n",
    "            break\n",
    "    if not flag:\n",
    "        data_test += [word]\n",
    "\n",
    "data_train = ' '.join(data_train)\n",
    "data_test = ' '.join(data_test)\n",
    "\n",
    "# возьмем в качестве теста первые 1000 символов романа Анна Каренина, а остальную часть добавим в трейн\n",
    "data_train += ' ' + data_test[1000:]\n",
    "data_test = data_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce483f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях в е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобное ф м достоевский находил в но\n"
     ]
    }
   ],
   "source": [
    "# печатаем тестовые данные\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dab28",
   "metadata": {},
   "source": [
    "## 1. Частотный метод по Шерлоку Холмсу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737c258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная фраза:\n",
      "\n",
      " анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом роман\n",
      "\n",
      " Закодированная фраза: \n",
      "\n",
      " гннгзыгьбнлнгзяилнзлрзсгжоузрнгжбнлвоузьяжгняшзмюшгзвямсвяпязнгтлнгбвсщзсвгшабъзгхяьлржяжзхьгряъзшсбзстгсвмлшобзсбжюлзчяуя лзиьдпзнгзиьдпгзыг игщзнбстгсвмлшгщзсбжющзнбстгсвмлшгзчязсшябждзэвязынлпгзязшбтноузйбннясвщузязмцешлзязшбьбзязсбжюбзязтбмяшбтбсыяжзиясвялнсвшбзмбшзвямсвяъьяжгнзальяыяпязиоугнлщзтгсвюзмбшзвямсвяъзгннгзыгьбнлнгзьяжгнзальяыяпязиоугнлщзгннгзыгьбнлнгзчяьгрлмгзсяшьбжбннлыяшзшсбинбшнясвюцзсяибь гнлщзнбяеотгънгщзсшяеяигзьгсыяшгннясвюзчяшбсвшяшгнлщздилшлвбмюнязсятбвгмлсюзшзэвяжзьяжгн\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# подсчет частот символов в романе Война и Мир\n",
    "frequency_dict_train = {}\n",
    "for char in data_train:\n",
    "    if char in frequency_dict_train:\n",
    "        frequency_dict_train[char] += 1 / len(data_train)\n",
    "    else:\n",
    "        frequency_dict_train[char] = 1 / len(data_train)\n",
    "# случайная перестановка символов\n",
    "alphabyte = list(alphabyte)\n",
    "alphabyte_new = alphabyte.copy()\n",
    "random.shuffle(alphabyte_new)\n",
    "dictionary_to_change = {i:j for i,j  in zip(alphabyte, alphabyte_new)}\n",
    "\n",
    "\n",
    "# кодировка текста согласно перестановки\n",
    "START = 0\n",
    "LENGTH = 500\n",
    "data_test_part = data_test[START:START + LENGTH]\n",
    "data_test_encoded = []\n",
    "for char in data_test_part:\n",
    "    data_test_encoded += [dictionary_to_change[char]]\n",
    "data_test_encoded = ''.join(data_test_encoded)\n",
    "print('Исходная фраза:\\n\\n {}\\n\\n Закодированная фраза: \\n\\n {}\\n'.format(data_test_part, data_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b914358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем по минимальному расстоянию по частотам в тесте и трейне\n",
    "def find_relationship(dict_train, dict_test):\n",
    "    key_in_use = set()\n",
    "    decode_dict = {}\n",
    "    for key_test, _ in sorted(dict_test.items(), key=lambda x: x[1], reverse=True):\n",
    "        min_dist = np.inf\n",
    "        min_key = None\n",
    "        for key_train, _ in sorted(dict_train.items(), key=lambda x: x[1], reverse=True):\n",
    "            if key_train not in key_in_use:\n",
    "                cur_dist = abs(dict_train[key_train] - dict_test[key_test])\n",
    "                if cur_dist < min_dist:\n",
    "                    min_dist = cur_dist\n",
    "                    min_key = key_train\n",
    "        key_in_use.add(min_key)\n",
    "        decode_dict[key_test] = min_key\n",
    "    return decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "885b524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расшифрованный текст: \n",
      " \n",
      " еаае пернатае оута тж иекзб жаекнатлзб рокеаос дгсе лодилочо аеятаенлиь илесюнй ещортжкок щрежой син ияеилдтсзн инкгт шобоэт урхч ае урхче пеэуеь анияеилдтсеь инкгь анияеилдтсе шо исонкх фло патче о сняазб ынааоильб о дъцст о снрн о инкгн о яндоснянипок уоилотаилсн днс лодилойрокеа ютропочо узбеать яеилг днс лодилой еаае пернатае рокеа ютропочо узбеать еаае пернатае шорежтде иосрнкнаатпос синуансаоилгъ иоунрэеать аноцзяейаеь исоцоуе реипосеааоилг шоснилсосеать хутстлндгао иоянледтиг с флок рокеа\n"
     ]
    }
   ],
   "source": [
    "# считаем частотность в тестовом отрывке\n",
    "frequency_dict_test_encoded = {}\n",
    "for char in data_test_encoded:\n",
    "    if char in frequency_dict_test_encoded:\n",
    "        frequency_dict_test_encoded[char] += 1 / len(data_test_encoded)\n",
    "    else:\n",
    "        frequency_dict_test_encoded[char] = 1 / len(data_test_encoded)\n",
    "\n",
    "# сопоставляем с ближайшей с частотами на трейне\n",
    "decode_dict = find_relationship(frequency_dict_train, frequency_dict_test_encoded)\n",
    "# расшифровываем тестовый текст\n",
    "data_test_decoded = ''\n",
    "for char in data_test_encoded:\n",
    "    data_test_decoded += decode_dict[char]\n",
    "print('Расшифрованный текст: \\n \\n {}'.format(data_test_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac778f3b",
   "metadata": {},
   "source": [
    "## 2 Частотная модель на базе биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9440217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подсчет частот биграмм в романе Война и мир\n",
    "frequency_dict_train = {}\n",
    "for i in range(len(data_train)-1):\n",
    "    bigram = data_train[i:i+2]\n",
    "    if bigram in frequency_dict_train:\n",
    "        frequency_dict_train[bigram] += 1\n",
    "    else:\n",
    "        frequency_dict_train[bigram] = 1\n",
    "\n",
    "        \n",
    "for key in frequency_dict_train:\n",
    "    frequency_dict_train[key] = (frequency_dict_train[key] + 1) / (len(data_train) + 34 ** 2)\n",
    "# Количество биграмм\n",
    "len(frequency_dict_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffedcb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расшифрованный текст: \n",
      " \n",
      "  т уе о  кбы чбетьал п оонтья  яееняемседаол зелчаетол охо новож иовкаи шесвинстя ал пы  ии  ж чесит вдоия зт споевапоуд н кя соикв льа огарниид лужслак ивыа рулидннуе  пглресторгопоая нрое че нмо е втвал иа тон тыо  нмамуо о  а оо  нк  х о па аснеодсии  нихиви о заэту и  н т уи о  квостнелатьнай теергоныто стурый чеил о тй я ще л счие заовмеон смесьегжеулв льь еблуносянытиько о ы па к сто еутнониналал ьнатм  о тмисколказ умл вадоу о погдувбулал  п али стоимрои тнлыжнонывстаененескимтаеннн э па \n"
     ]
    }
   ],
   "source": [
    "# считаем частотность биграмм в тестовом отрывке\n",
    "frequency_dict_test_encoded = {}\n",
    "for i in range(len(data_test_encoded)-1):\n",
    "    bigram = data_train[i:i+2]\n",
    "    if bigram in frequency_dict_test_encoded:\n",
    "        frequency_dict_test_encoded[bigram] += 1 / len(data_test_encoded)\n",
    "    else:\n",
    "        frequency_dict_test_encoded[bigram] = 1 / len(data_test_encoded)\n",
    "\n",
    "\n",
    "# сопоставляем по убыванию с частотами на трейне\n",
    "decode_dict = find_relationship(frequency_dict_train, frequency_dict_test_encoded)\n",
    "# расшифровываем тестовый текст\n",
    "data_test_decoded_bigram = ''\n",
    "for i in range(0, len(data_test_encoded), 2):\n",
    "    bigram = data_train[i:i+2]\n",
    "    data_test_decoded_bigram += decode_dict[bigram]\n",
    "print('Расшифрованный текст: \\n \\n {}'.format(data_test_decoded_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e2baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля отгаданных символов модели на униграммах: 0.094 Доля отгаданных символов модели на биграммах: 0.082\n"
     ]
    }
   ],
   "source": [
    "# сравниваем униграммы и биграммы\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "set_bigram = set()\n",
    "for i, j, k in zip(data_test_decoded, data_test_decoded_bigram, data_test):\n",
    "    if i == j:\n",
    "        counter1 += 1\n",
    "    if j == k:\n",
    "        counter2 += 1\n",
    "\n",
    "print(\"Доля отгаданных символов модели на униграммах: {} \\\n",
    "Доля отгаданных символов модели на биграммах: {}\".format(counter1 / len(data_test_decoded), \n",
    "                                                         counter2 / len(data_test_decoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1fa356",
   "metadata": {},
   "source": [
    "__Вывод: униграммы работают с 33 + 1 символами, а биграммы с 34 * 34 биграммами, частотный метод лучше работает с униграммами  на небольшом корпусе данных, на больших лучше с биграммами__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8035db",
   "metadata": {},
   "source": [
    "## 3. Улучшение метода биграмм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c49c4",
   "metadata": {},
   "source": [
    "_Идея: в цикле запускаем \"умный\" случайный поиск по типу Метрополиса-Хастинга:_\n",
    "\n",
    "        - сэмплируем две буквы, будем их менять между собой\n",
    "        - считаем новое значение правдоподобия входного текста (1000 первых букв Анны Каренины) по частотной статистике биграмм на трейне (Война и мир + Анна Каренина).\n",
    "        - сравниваем отношение вероятностей получить данный текст до замены и после со случайным числом из диапазона [0,1). Если отношение больше, то принимаем замену, иначе нет.\n",
    "\n",
    "_Будем запускать такой поиск много раз и выбирем оптимальную декодировку по критерию максимального правдоподобия._ \n",
    "_Как и в любых моделях жадного поиска это позволит получить разные локальные минимумы (строго, разный конечный результат)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35d4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(reverse_dict, text_encoded):\n",
    "    text_decoded = ''\n",
    "    for char in text_encoded:\n",
    "        text_decoded += reverse_dict[char]\n",
    "    return text_decoded\n",
    "\n",
    "def calculate_log_prob(reverse_dict, text_encoded, freq_dict, n_gram=2):\n",
    "    decoded_text = decode_text(reverse_dict, text_encoded)\n",
    "    log_res = 0\n",
    "    for ind in range(len(decoded_text) - 1):\n",
    "        bigram = decoded_text[ind: ind + 2]\n",
    "        bigram_value = freq_dict.get(bigram)\n",
    "        if bigram_value is None:\n",
    "            bigram_value = 1 / (len(decoded_text) + 33 ** 2)\n",
    "        log_res += np.log(bigram_value)\n",
    "    return log_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0b47fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:04<00:00, 1542.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:0 best score: -2803.436442337429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:05<00:00, 1518.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:1 best score: -2803.436442337429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:07<00:00, 1486.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:2 best score: -2803.436442337429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:07<00:00, 1478.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:3 best score: -2751.1571548629768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:07<00:00, 1475.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:4 best score: -2750.3832213710266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERS = 100_000\n",
    "NUM_TRIALS = 5\n",
    "for j in range(NUM_TRIALS):\n",
    "\n",
    "    ans = {key: key for key in alphabyte}\n",
    "    cur_reverse = {j:i for i, j in ans.items()}\n",
    "\n",
    "    prev_log_score = calculate_log_prob(cur_reverse, data_test_encoded, frequency_dict_train)\n",
    "    if j == 0:\n",
    "        list_of_keys = list(ans.keys())\n",
    "        best_score = prev_log_score\n",
    "        best_dict = ans.copy()\n",
    "        best_reverse_dict = cur_reverse.copy()\n",
    "\n",
    "    for i in trange(NUM_ITERS):\n",
    "\n",
    "        key1 = random.choice(list_of_keys)\n",
    "        key2 = random.choice(list_of_keys)\n",
    "        ans_new = ans.copy()\n",
    "        ans_new[key1], ans_new[key2] = ans_new[key2], ans_new[key1]\n",
    "        \n",
    "        cur_reverse = {j:i for i, j in ans_new.items()}\n",
    "        new_log_score = calculate_log_prob(cur_reverse, data_test_encoded, frequency_dict_train)\n",
    "        score = np.exp(new_log_score - prev_log_score)\n",
    "    \n",
    "        if score >= np.random.uniform(0, 1):\n",
    "            prev_log_score = new_log_score\n",
    "            ans = ans_new.copy()\n",
    "                \n",
    "        if new_log_score > best_score:\n",
    "            best_score = new_log_score\n",
    "            best_dict = ans.copy() \n",
    "            best_reverse_dict = cur_reverse.copy()\n",
    "    print('trial number:{} best score: {}'.format(j, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34d410c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'анна каденина омин из салых зналенитых доланов рьва торстого начинается ставшей афодизлол фдазой все счастривые сельи похоъи мдуг на мдуга каъмая несчастривая селья несчастрива по своелу это книга о вечных женностях о рюбви о веде о селье о черовеческол мостоинстве рев торстойдолан шидокого мыхания часть рев торстой анна каденина долан шидокого мыхания анна каденина подазира совделенников всемневностью сомедъания необычайная свобома даскованность повествования умивитерьно сочетарись в этол долан'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text(best_reverse_dict, data_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa68647",
   "metadata": {},
   "source": [
    "Вполне можно восстановить текст !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6aec6",
   "metadata": {},
   "source": [
    "## 4. Расшифровка сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbadd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙\\\n",
    "↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴\\\n",
    "⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴\\\n",
    "↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "604edc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:31<00:00, 3198.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:0 best score: -1360.1069707080533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:31<00:00, 3220.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:1 best score: -1360.1069707080533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:31<00:00, 3198.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:2 best score: -1238.4360269957488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:33<00:00, 2941.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:3 best score: -1238.4360269957488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:34<00:00, 2879.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number:4 best score: -1238.4360269957488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERS = 100_000\n",
    "NUM_TRIALS = 5\n",
    "\n",
    "uniques = list(set(message)) + [None] * (len(alphabyte) - len(list(set(message))))\n",
    "for j in range(NUM_TRIALS):\n",
    "    \n",
    "    ans = {i:j for i,j in zip(alphabyte, uniques)}\n",
    "    cur_reverse = {j:i for i, j in ans.items() if j is not None}\n",
    "\n",
    "    prev_log_score = calculate_log_prob(cur_reverse, message, frequency_dict_train)\n",
    "    if j == 0:\n",
    "        list_of_keys = list(ans.keys())\n",
    "        best_score = prev_log_score\n",
    "        best_dict = ans.copy()\n",
    "        best_reverse_dict = cur_reverse.copy()\n",
    "\n",
    "    for i in trange(NUM_ITERS):\n",
    "\n",
    "        key1 = random.choice(list_of_keys)\n",
    "        key2 = random.choice(list_of_keys)\n",
    "        ans_new = ans.copy()\n",
    "        ans_new[key1], ans_new[key2] = ans_new[key2], ans_new[key1]\n",
    "        \n",
    "        cur_reverse = {j:i for i, j in ans_new.items()}\n",
    "        new_log_score = calculate_log_prob(cur_reverse, message, frequency_dict_train)\n",
    "        score = np.exp(new_log_score - prev_log_score)\n",
    "    \n",
    "        if score >= np.random.rand():\n",
    "            prev_log_score = new_log_score\n",
    "            ans = ans_new.copy()\n",
    "                \n",
    "        if new_log_score > best_score:\n",
    "            best_score = new_log_score\n",
    "            best_dict = ans.copy() \n",
    "            best_reverse_dict = cur_reverse.copy()\n",
    "    print('trial number:{} best score: {}'.format(j, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb87fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого соожшения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный жалл за послемнее четвертое замание курса ботя конечно я ничего не ожешах'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text(best_reverse_dict, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06169d70",
   "metadata": {},
   "source": [
    "## 6 Применение схемы (бонус)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289148f",
   "metadata": {},
   "source": [
    "В максимально общем виде мы решили следующую задачу: имеется некоторая последовательность неизвестных по отдельности сущностей и их частота появления в других последовательностях, требуется идентификация сущностей в данной последовательности по их частоте появления. \n",
    "\n",
    "Это может быть полезно в задачах, где прямая идентификация затруднена или невозможна.\n",
    "- по вычислительным или фундаментальным причинам (поиск элементарных частиц и осколков частиц в физике), сэмплирование в квантовой механике и квантовой химии (поиск конфигурации сложных молекул по спектру и минимуму энергий, кластерные образования молекул).\n",
    "- биология: геномные последовательности, возможно под действием шума или опосредованными методами не дающими возможность идентифицировать аминокислоту и/или структуру по отдельности.\n",
    "- расшифровка языков по сущностям (если народы жили в одной и той же среде обитания, то частоты использования слов для важнейших сущностей могут быть схожими). Для научных понятий это точно верно в силу универсальности науки (см. повесть \"Универсальный язык\"). Скорее это вспомогательный метод. Сейчас только древние и древнейшие языки требуют декодировку, а в них нет научных понятий. Возможно, это будет полезно, если человечество сможет преодолеть оковы капитализма и будет находить руины индустриальных цивилизаций в других галактиках.\n",
    "\n",
    "Как и в методах сэмплирования можно использовать для решения задачи дискретной оптимизации, либо непрерывной оптимизации недифференцируемого функционала."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
