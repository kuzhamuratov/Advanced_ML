{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "players.pkl  results.pkl  tournaments.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls chgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./chgk/players.pkl\", \"rb\") as file:\n",
    "    player_data = pickle.load(file)\n",
    "\n",
    "with open(\"./chgk/results.pkl\", \"rb\") as file:\n",
    "    result_data = pickle.load(file)\n",
    "\n",
    "with open(\"./chgk/tournaments.pkl\", \"rb\") as file:\n",
    "    tournament_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'name': 'Алексей', 'patronymic': None, 'surname': 'Абабилов'}\n"
     ]
    }
   ],
   "source": [
    "print(player_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'team': {'id': 242, 'name': 'Команда Азимова', 'town': {'id': 21, 'name': 'Баку'}}, 'mask': None, 'current': {'name': 'Команда Азимова', 'town': {'id': 21, 'name': 'Баку'}}, 'questionsTotal': 0, 'synchRequest': None, 'position': 1, 'controversials': [], 'flags': [], 'teamMembers': [{'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 476, 'name': 'Анар', 'patronymic': 'Беюкага оглы', 'surname': 'Азимов'}}, {'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 878, 'name': 'Фариз', 'patronymic': 'Наим оглы', 'surname': 'Аликишибеков'}}, {'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 1872, 'name': 'Аднан', 'patronymic': 'Фариз оглы', 'surname': 'Ахундов'}}, {'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 13721, 'name': 'Балаш', 'patronymic': 'Алекпер оглы', 'surname': 'Касумов'}}, {'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 22132, 'name': 'Анар', 'patronymic': 'Джафар оглы', 'surname': 'Наджафли'}}, {'flag': None, 'usedRating': 0, 'rating': 0, 'player': {'id': 22133, 'name': 'Рауф', 'patronymic': 'Джафар оглы', 'surname': 'Наджафли'}}]}\n"
     ]
    }
   ],
   "source": [
    "print(result_data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'name': 'Чемпионат Южного Кавказа', 'dateStart': '2003-07-25T00:00:00+04:00', 'dateEnd': '2003-07-27T00:00:00+04:00', 'type': {'id': 2, 'name': 'Обычный'}, 'season': '/seasons/1', 'orgcommittee': [], 'synchData': None, 'questionQty': None}\n"
     ]
    }
   ],
   "source": [
    "print(tournament_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mask(inp):\n",
    "    uniques = set(inp)\n",
    "    return '1' in uniques and '0' in uniques and len(uniques) == 2\n",
    "\n",
    "# filtering data\n",
    "keys_to_train = []\n",
    "keys_to_test = []\n",
    "keys_to_delete = [] # care of memory\n",
    "for key, value in tournament_data.items():\n",
    "    if '2019-' in value['dateStart']:\n",
    "        count_mask = 0\n",
    "        for element in result_data[key]:\n",
    "            if ('mask' in element and 'teamMembers' in element and element['mask'] \n",
    "                and element['teamMembers']):\n",
    "                count_mask = 1\n",
    "        if count_mask > 0:\n",
    "            keys_to_train.append(key)\n",
    "        \n",
    "\n",
    "        \n",
    "    elif '2020-' in value['dateStart']:\n",
    "        count_mask = 0\n",
    "        for element in result_data[key]:\n",
    "            if ('mask' in element and 'teamMembers' in element and element['mask'] \n",
    "                and element['teamMembers'] and check_mask(element['mask'])):\n",
    "                count_mask += 1\n",
    "        if count_mask == len(result_data[key]) and count_mask > 0:\n",
    "            keys_to_test.append(key)\n",
    "    else:\n",
    "        keys_to_delete.append(key)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_to_delete:\n",
    "    del tournament_data[key]\n",
    "    del result_data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 133\n"
     ]
    }
   ],
   "source": [
    "print(len(keys_to_train), len(keys_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "\n",
    "y_train = []\n",
    "\n",
    "team_ids = []\n",
    "\n",
    "for key in keys_to_train:\n",
    "    tourn_tmp = tournament_data[key]['id']\n",
    "    for team in result_data[key]:\n",
    "        answers = team['mask']\n",
    "        team_members = team['teamMembers']\n",
    "        if not answers:\n",
    "            continue\n",
    "        for index, answer in enumerate(answers):\n",
    "            for team_member in team_members:\n",
    "                X_train.append([tourn_tmp, index, team_member['player']['id']])\n",
    "                y_train.append(answer)\n",
    "                team_ids.append(team['team']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_to_norm_id = {}\n",
    "answer_to_norm_id = {}\n",
    "\n",
    "counter_player = 0\n",
    "counter_answer = 0\n",
    "for i in range(len(X_train)):\n",
    "    data_element = X_train[i]\n",
    "\n",
    "    if tuple(data_element[:2]) not in answer_to_norm_id:\n",
    "        answer_to_norm_id[tuple(data_element[:2])] = counter_answer\n",
    "        counter_answer += 1\n",
    "    if data_element[2] not in player_to_norm_id:\n",
    "        player_to_norm_id[data_element[2]] = counter_player\n",
    "        counter_player += 1\n",
    "    \n",
    "    X_train[i] = [answer_to_norm_id[tuple(data_element[:2])], player_to_norm_id[data_element[2]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_ids = []\n",
    "for i in range(len(X_train)):\n",
    "    data_element = X_train_copy[i]\n",
    "    question_ids.append(answer_to_norm_id[tuple(data_element[:2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)\n",
    "y_train[y_train=='X'] = '?'\n",
    "indixes = (y_train != '?')\n",
    "y_train = y_train[indixes]\n",
    "X_train = X_train[indixes]\n",
    "\n",
    "team_ids = np.array(team_ids)\n",
    "question_ids = np.array(question_ids)\n",
    "\n",
    "team_ids = team_ids[indixes]\n",
    "question_ids = question_ids[indixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33385 59101\n"
     ]
    }
   ],
   "source": [
    "print(counter_answer, counter_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(map(int, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot encoding\n",
    "X_train_one_hot = sparse.lil_matrix((len(X_train), counter_answer + counter_player), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20910740, 92486)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    ind1, ind2 = X_train[i]\n",
    "    X_train_one_hot[i, ind1]  = 1\n",
    "    X_train_one_hot[i, counter_answer + ind2]  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "данные на входе - объединение one-hot вектора игрока и one-hot вектора вопроса, по ним предсказываем смог ли игрок ответить на данный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.7 s, sys: 252 ms, total: 55.9 s\n",
      "Wall time: 55.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='saga', tol=0.1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(tol=1e-1, solver='saga')\n",
    "model.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7621513633663849"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, model.predict(X_train_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Оценка качества рейтинг системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем что команда отвечает на вопрос если хотя бы один ее член может ответить на вопрос т.е.:\n",
    "\n",
    "$P(\\textbf{team}) = [1 - p(\\textbf{player1 failed}) \\times p(\\textbf{player2 failed})... \\times p(\\textbf{playerN failed})]$\n",
    "\n",
    "Оцениваем по **0 вопросу** (Можно в среднем по вопросам, разницы нет).\n",
    "\n",
    "Сравниваем с частотой ответа команды на вопросы - количество единичек в маске"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работаем обязательно на тест сете: **keys_to_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_labels_pred(model):\n",
    "    labels_tournament = []\n",
    "    tournaments_players = []\n",
    "    id_to_except = []\n",
    "    for key in keys_to_test:\n",
    "        \n",
    "        \n",
    "        flag_to_except = False\n",
    "        tournament_result = []\n",
    "        \n",
    "        tournament_player_team = []\n",
    "        for team in result_data[key]:\n",
    "            team_id = team['team']['id']\n",
    "            \n",
    "            target_score = sum(list(map(int, team['mask'])))\n",
    "            team_score = 1\n",
    "            for player in team['teamMembers']:\n",
    "                if player['player']['id'] in player_to_norm_id:\n",
    "                    tmp = sparse.lil_matrix((1, counter_answer + counter_player), dtype=int)\n",
    "                    tmp[0, counter_answer + player_to_norm_id[player['player']['id']]] = 1\n",
    "                    tmp[0, 0] = 1\n",
    "                    team_score *= model.predict_proba(tmp)[0, 0]\n",
    "                \n",
    "                else:\n",
    "                    flag_to_except = False\n",
    "            \n",
    "            tournament_player_team += [[team_id, 1 - team_score]]\n",
    "            tournament_result += [[team_id, target_score]]\n",
    "        if not flag_to_except:\n",
    "            tournaments_players.append(tournament_player_team)\n",
    "            labels_tournament.append(tournament_result)\n",
    "    return labels_tournament, tournaments_players\n",
    "\n",
    "def calculate_correlations(labels_tournament, tournaments_players):\n",
    "    ans_spearman = []\n",
    "    ans_kendall = []\n",
    "    assert len(labels_tournament) == len(tournaments_players)\n",
    "    for target, pred in zip(labels_tournament, tournaments_players):\n",
    "        pred = np.array(pred)\n",
    "        target = np.array(target)\n",
    "        ans_spearman += [stats.spearmanr(pred[:, 1], target[:, 1]).correlation]\n",
    "        ans_kendall += [stats.kendalltau(pred[:, 1], target[:, 1]).correlation]\n",
    "    print('Spearman correlation: {} Kendall correlation: {}'.format(\n",
    "        sum(ans_spearman) / len(ans_spearman), sum(ans_kendall) / len(ans_kendall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.7683993921664228 Kendall correlation: 0.6113482574828197\n",
      "CPU times: user 11 s, sys: 36.8 ms, total: 11.1 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# считаем на тестовых данных корреляции Спирмана и Кэнделла\n",
    "labels, preds = calculate_labels_pred(model)\n",
    "calculate_correlations(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Учет командной игры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея:\n",
    "\n",
    "- В предыдущем пункте мы выучили вероятности того что конкретный игрок ответит на конкретный вопрос, без учета команды;\n",
    "\n",
    "- В этом пункте учтем наличие команды как скрытой переменной: вектор $Z$ состоит из 4 вероятностей $p(\\textbf{player} | \\textbf{team})$, переменные тут бинарные;\n",
    "\n",
    "- $p(\\textbf{player}=0|\\textbf{team}=0) = 1, p(\\textbf{player}=1|\\textbf{team}=0) = 0$, если команда не ответила, то ни один игрок не знал ответ;\n",
    "\n",
    "- $p(\\textbf{player}=1|\\textbf{team}=1), p(\\textbf{player}=0 | \\textbf{team}=1)$ - нетривиальные вероятности, их и будем учить;\n",
    "\n",
    "- В EM алгоритме на Е-шаге будем пересчитывать вероятности игрока ответить на вопрос с учетом правильного ответа команды: $\\large p(\\textbf{player}=1 | \\textbf{team}=1) = \\frac{p(\\textbf{team}=1|\\textbf{player}=1)\\times p(\\textbf{player}=1)}{p(\\textbf{team}=1)} = \\frac{p(\\textbf{player}=1)}{p(\\textbf{team}=1)}$;\n",
    "\n",
    "\n",
    "\n",
    "- в M-шаге учим логистическую регрессию как в пункте **3 Оценка качества рейтинг системы** на новых вероятностях из E-шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в EM схеме нужна логистическая регрессия с непрерывными значениями таргетов\n",
    "class LogisticRegressionWithSoftTargets:\n",
    "    def __init__(self, model):\n",
    "        self.number_iterations = 100_000\n",
    "        self.lr = 10\n",
    "        self.batch_size = 1000\n",
    "        self.tol = 0.0000001\n",
    "        self.weights = np.hstack((model.intercept_, model.coef_[0]))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = sparse.hstack([np.ones(len(y)).reshape(-1, 1), X], format='csr')\n",
    "        loss_list = []\n",
    "        prev_loss_mean_val = np.inf\n",
    "        for i in range(self.number_iterations):\n",
    "            indixes = np.random.choice(X.shape[0], self.batch_size)\n",
    "            X_batch = X[indixes, :]\n",
    "            y_batch = y[indixes]\n",
    "            predictions = 1 / (1 + np.exp(-X_batch.dot(self.weights)))\n",
    "            \n",
    "            loss = -np.mean(y_batch * np.log(predictions) + (1 - y_batch) * np.log(1 - predictions))\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            if i> 0 and i % 1000 == 0:\n",
    "                new_loss_mean_val = np.mean(loss_list)\n",
    "                if prev_loss_mean_val - new_loss_mean_val < self.tol:\n",
    "                    print(\"NLL mean: \", new_loss_mean_val)\n",
    "                    break\n",
    "                loss_list = []\n",
    "                prev_loss_mean_val = new_loss_mean_val\n",
    "            \n",
    "            gradient = -X_batch.T.dot(y_batch - predictions) / len(y_batch)\n",
    "            self.weights -= self.lr * gradient\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = sparse.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
    "\n",
    "        predictions = 1 / (1 + np.exp(-X.dot(self.weights)))\n",
    "        return np.hstack(((1 - predictions).reshape(-1, 1), predictions.reshape(-1, 1)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.7683993921664228 Kendall correlation: 0.6113482574828197\n",
      "NLL mean:  0.3914276321493574\n",
      "Spearman correlation: 0.7903297234741925 Kendall correlation: 0.6335501081591189\n",
      "NLL mean:  0.35069600211470864\n",
      "Spearman correlation: 0.801188679371039 Kendall correlation: 0.6451459501355014\n",
      "NLL mean:  0.33096014189128714\n",
      "Spearman correlation: 0.8066302792629125 Kendall correlation: 0.6510665191978618\n",
      "NLL mean:  0.320372321999943\n",
      "Spearman correlation: 0.8099437208466164 Kendall correlation: 0.6541825924760943\n",
      "NLL mean:  0.3168957142929127\n",
      "Spearman correlation: 0.8132352489666265 Kendall correlation: 0.6579823417330826\n",
      "NLL mean:  0.3140378935207219\n",
      "Spearman correlation: 0.8138624038733894 Kendall correlation: 0.6590524469390375\n",
      "NLL mean:  0.3134119346680254\n",
      "Spearman correlation: 0.8144222459004987 Kendall correlation: 0.6593868094184022\n",
      "NLL mean:  0.3123075342586997\n",
      "Spearman correlation: 0.8154591494330191 Kendall correlation: 0.6607789386677916\n",
      "NLL mean:  0.31298554704517817\n",
      "Spearman correlation: 0.8162066770453515 Kendall correlation: 0.660863463809229\n",
      "NLL mean:  0.3135308249932842\n",
      "Spearman correlation: 0.8178818143107964 Kendall correlation: 0.6625060179007174\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegressionWithSoftTargets(model)\n",
    "\n",
    "\n",
    "labels, preds = calculate_labels_pred(model)\n",
    "calculate_correlations(labels, preds)\n",
    "\n",
    "for _ in range(10):\n",
    "    preds = estimator.predict_proba(X_train_one_hot)\n",
    "    \n",
    "    # E step\n",
    "    \n",
    "    data_team = pd.DataFrame({'team': team_ids, 'question': question_ids, \n",
    "                        'fail_of_prediction': preds[:, 0]})\n",
    "    dictionary_state = {}\n",
    "    for team, question, fail_prediction in data_team.values:\n",
    "        if (team, question) in dictionary_state:\n",
    "            dictionary_state[(team, question)] *= fail_prediction\n",
    "        else:\n",
    "            dictionary_state[(team, question)] = fail_prediction\n",
    "    \n",
    "    new_columns_vals = []\n",
    "    for team, question, fail_prediction in data_team.values:\n",
    "        new_columns_vals += [1 - dictionary_state[(team, question)]]\n",
    "    \n",
    "    data_team['team_success'] = new_columns_vals\n",
    "    del dictionary_state, new_columns_vals\n",
    "    \n",
    "    z = np.clip((1 - data_team['fail_of_prediction'].values) / data_team['team_success'].values, 0, 1)\n",
    "    \n",
    "\n",
    "    \n",
    "    # обнуляем вероятности Z когда команда не ответила на вопрос\n",
    "    z[np.array(y_train) == 0] = 0\n",
    "    \n",
    "    \n",
    "    # M step\n",
    "    estimator.fit(X_train_one_hot, z)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # считаем метрики на тест сете (за 2020 год)\n",
    "    labels, predictions = calculate_labels_pred(estimator)\n",
    "    calculate_correlations(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Рейтинг лист турниров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_answer = {value:id_ for id_, value in answer_to_norm_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_coefs = model.coef_[0][:counter_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_scores = {}\n",
    "for id_ in id_to_answer:\n",
    "    tournament, _  = id_to_answer[id_]\n",
    "    if tournament in tournament_scores:\n",
    "        tournament_scores[tournament] += [answer_coefs[id_]]\n",
    "    else:\n",
    "        tournament_scores[tournament] = [answer_coefs[id_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем медианную сложность вопроса у каждого турнира\n",
    "tournament_scores = {key: np.median(score) for key, score in tournament_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tournament with low value is hard\n",
    "tournament_scores = sorted(tournament_scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чемпионат Санкт-Петербурга. Первая лига\n",
      "Первенство правого полушария\n",
      "Угрюмый Ёрш\n",
      "Чемпионат Минска. Лига А. Тур четвёртый\n",
      "Воображаемый музей\n",
      "Кубок городов\n",
      "Синхрон высшей лиги Москвы\n",
      "Записки охотника\n",
      "Тихий Донец: омут первый\n",
      "Чемпионат Таджикистана\n"
     ]
    }
   ],
   "source": [
    "# сильнейшие турниры\n",
    "for i in range(10):\n",
    "    print(tournament_data[tournament_scores[i][0]]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чемпионат Санкт-Петербурга. Первая лига\n",
      "Шестой киевский марафон. Асинхрон\n",
      "Синхрон Лиги Разума\n",
      "(а)Синхрон-lite. Лига старта. Эпизод V\n",
      "(а)Синхрон-lite. Лига старта. Эпизод III\n",
      "Студенческий чемпионат Калининградской области\n",
      "(а)Синхрон-lite. Лига старта. Эпизод IX\n",
      "(а)Синхрон-lite. Лига старта. Эпизод IV\n",
      "Школьная лига\n",
      "(а)Синхрон-lite. Лига старта. Эпизод VII\n"
     ]
    }
   ],
   "source": [
    "# слабейшие турниры\n",
    "for i in range(10):\n",
    "    print(tournament_data[tournament_scores[-i][0]]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты соответствуют ожиданиям:**\n",
    "\n",
    "Среди сильнейших турниров: чемпионаты стран и крупнейших городов России.\n",
    "\n",
    "Среди слабейших турниров: Школьная лига + Лига старта"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
